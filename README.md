# ğŸ” Financial Fraud Detection System â€” Explainable AI

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![XGBoost](https://img.shields.io/badge/ML-XGBoost-orange.svg)](https://xgboost.readthedocs.io/)
[![SHAP](https://img.shields.io/badge/Explainability-SHAP-green.svg)](https://shap.readthedocs.io/)
[![Streamlit](https://img.shields.io/badge/Dashboard-Streamlit-FF4B4B.svg)](https://streamlit.io/)
[![Flask](https://img.shields.io/badge/API-Flask-000000.svg)](https://flask.palletsprojects.com/)

> An enterprise-grade fraud detection system with explainable AI capabilities, featuring machine learning-based transaction scoring, SHAP visualizations, an interactive Streamlit dashboard, and a production-ready Flask REST API.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Usage](#usage)
  - [Training the Model](#training-the-model)
  - [Streamlit Dashboard](#streamlit-dashboard)
  - [Flask REST API](#flask-rest-api)
  - [Jupyter Notebooks](#jupyter-notebooks)
- [Model Performance](#model-performance)
- [API Documentation](#api-documentation)
- [Explainability (SHAP)](#explainability-shap)
- [Docker Deployment](#docker-deployment)
- [Project Architecture](#project-architecture)
- [Model Card](#model-card)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

This Financial Fraud Detection System demonstrates how modern machine learning and explainable AI techniques can be applied to identify fraudulent transactions while maintaining transparency and interpretability. The system is designed to handle highly imbalanced datasets and provides both batch and real-time scoring capabilities.

### ğŸ“ About This Project

This is a **portfolio project** demonstrating end-to-end machine learning engineering capabilities:

- **Problem**: Detect fraudulent financial transactions in imbalanced datasets (1.5% fraud rate)
- **Solution**: XGBoost classifier with SHAP explainability
- **Impact**: 95%+ ROC-AUC, 70%+ recall @ top 1% (catching most fraud with minimal false positives)
- **Tech Stack**: Python, XGBoost, SHAP, Streamlit, Flask, scikit-learn
- **Deployment**: REST API + interactive dashboard + Docker support

**Why this matters:** Financial fraud costs businesses billions annually. This system demonstrates how modern ML and explainable AI can detect fraud while maintaining transparency for regulatory compliance.

---

## âœ¨ Features

### Core Capabilities

âœ… **Machine Learning Pipeline**
- XGBoost classifier optimized for imbalanced data (scale_pos_weight)
- 5-fold stratified cross-validation
- Comprehensive metrics: ROC-AUC, PR-AUC, Recall@Top1%, Precision@Top1%, F1-Score
- Feature importance analysis
- Model serialization for deployment

âœ… **Explainable AI (SHAP)**
- Global feature importance (summary plots)
- Local explanations (force plots, waterfall plots)
- Feature interaction analysis
- Regulatory compliance-ready transparency

âœ… **Interactive Dashboard (Streamlit)**
- Upload CSV files for batch fraud detection
- Real-time fraud probability predictions
- Interactive SHAP visualizations
- Risk score distribution plots
- Adjustable detection threshold slider
- Export flagged transactions

âœ… **Production REST API (Flask)**
- `/health` - Health check endpoint
- `/score` - Single or batch transaction scoring
- JSON input/output format
- Real-time predictions (sub-second latency)
- Error handling and validation

âœ… **Comprehensive Documentation**
- Complete setup guides
- API documentation
- Model card (ethics, limitations, fairness)
- Jupyter notebooks for learning
- Docker deployment instructions

---

## ğŸ“‚ Project Structure
```
fraud-xai/
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ transactions.csv          # 100K synthetic transactions (9.4 MB)
â”‚   â””â”€â”€ processed/                     # Processed datasets (generated at runtime)
â”‚
â”œâ”€â”€ ğŸ“ docs/
â”‚   â”œâ”€â”€ COMPLETION_CHECKLIST.md       # Project deliverables checklist
â”‚   â”œâ”€â”€ FINAL_DELIVERY.md             # Complete delivery document
â”‚   â”œâ”€â”€ PROJECT_SUMMARY.md            # Feature overview
â”‚   â”œâ”€â”€ QUICK_REFERENCE.md            # One-page quick guide
â”‚   â”œâ”€â”€ QUICKSTART.md                 # Quick start guide
â”‚   â””â”€â”€ START_HERE.md                 # Navigation guide
â”‚
â”œâ”€â”€ ğŸ“ models/
â”‚   â”œâ”€â”€ fraud_model.pkl               # Trained XGBoost model (generated)
â”‚   â”œâ”€â”€ preprocessor.pkl              # Feature transformer (generated)
â”‚   â””â”€â”€ training_metadata.json        # Model metrics (generated)
â”‚
â”œâ”€â”€ ğŸ“ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb                  # Exploratory data analysis
â”‚   â”œâ”€â”€ 02_train_model.ipynb          # Interactive model training
â”‚   â””â”€â”€ 03_explainability.ipynb       # SHAP analysis & visualizations
â”‚
â”œâ”€â”€ ğŸ“ reports/
â”‚   â”œâ”€â”€ model_card.md                 # Model documentation & ethics
â”‚   â”œâ”€â”€ shap_summary.png              # Global SHAP importance (generated)
â”‚   â”œâ”€â”€ confusion_matrix.png          # Confusion matrix (generated)
â”‚   â”œâ”€â”€ roc_curve.png                 # ROC curve (generated)
â”‚   â””â”€â”€ pr_curve.png                  # Precision-Recall curve (generated)
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ generate_data.py              # Synthetic transaction generator
â”‚   â”œâ”€â”€ features.py                   # Feature engineering pipeline
â”‚   â”œâ”€â”€ train.py                      # Model training module
â”‚   â”œâ”€â”€ evaluate.py                   # Model evaluation & metrics
â”‚   â”œâ”€â”€ explain.py                    # SHAP explainability
â”‚   â”œâ”€â”€ app_dashboard.py              # Streamlit interactive dashboard
â”‚   â””â”€â”€ serve_api.py                  # Flask REST API
â”‚
â”œâ”€â”€ ğŸ“ tests/
â”‚   â””â”€â”€ test_api.py                   # API endpoint tests
â”‚
â”œâ”€â”€ ğŸ“„ .gitignore                      # Git ignore rules
â”œâ”€â”€ ğŸ“„ Dockerfile                      # Docker container definition
â”œâ”€â”€ ğŸ“„ docker-compose.yml              # Docker Compose configuration
â”œâ”€â”€ ğŸ“„ LICENSE                         # MIT License
â”œâ”€â”€ ğŸ“„ README.md                       # This file
â”œâ”€â”€ ğŸ“„ requirements.txt                # Python dependencies
â”œâ”€â”€ ğŸ“„ setup.py                        # Package setup configuration
â”œâ”€â”€ ğŸ“„ SETUP_GUIDE.md                  # Detailed setup instructions
â”œâ”€â”€ ğŸ“„ quick_train.py                  # Fast model training script
â”œâ”€â”€ ğŸ“„ train_pipeline.py               # Complete training pipeline
â””â”€â”€ ğŸ“„ verify_project.py               # Project structure verification
```

**Note:** Files marked "(generated)" are created when you run training scripts.

---

## ğŸš€ Installation

### Prerequisites

- Python 3.9 or higher
- pip (Python package manager)
- 4GB+ RAM recommended
- (Optional) Docker for containerized deployment

### Step 1: Clone Repository
```bash
git clone https://github.com/YOUR_USERNAME/fraud-detection-xai.git
cd fraud-detection-xai
```

### Step 2: Create Virtual Environment (Recommended)
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate

# On macOS/Linux:
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

**Installation time:** 2-3 minutes

---

## âš¡ Quick Start

### Option 1: Use Pre-Generated Data (Fastest)

The repository includes a pre-generated dataset of 100,000 transactions. Skip directly to training:
```bash
# Train model
python quick_train.py

# Launch dashboard
streamlit run src/app_dashboard.py
```

Dashboard opens at: **http://localhost:8501**

### Option 2: Generate Fresh Data
```bash
# Generate new synthetic data
python src/generate_data.py

# Train model
python quick_train.py

# Launch dashboard
streamlit run src/app_dashboard.py
```

### Option 3: Full Pipeline with Notebooks
```bash
# Launch Jupyter
jupyter notebook notebooks/

# Run notebooks in order:
# 1. 01_eda.ipynb - Explore data
# 2. 02_train_model.ipynb - Train model interactively
# 3. 03_explainability.ipynb - Analyze SHAP explanations
```

---

## ğŸ“– Usage

### Training the Model

#### Quick Training (Recommended)
```bash
python quick_train.py
```

**Output:**
- `models/fraud_model.pkl` - Trained XGBoost model
- `models/preprocessor.pkl` - Feature preprocessing pipeline
- Console displays: ROC-AUC, PR-AUC, and training metrics

#### Full Training Pipeline
```bash
python train_pipeline.py
```

**This includes:**
- Data generation
- Feature engineering
- Model training with cross-validation
- Comprehensive evaluation
- SHAP explainer generation

**Expected Performance:**
- ROC-AUC: ~0.95+
- PR-AUC: ~0.85+
- Recall @ Top 1%: ~70%+
- F1-Score: ~0.75+

---

### Streamlit Dashboard

Launch the interactive analyst dashboard:
```bash
streamlit run src/app_dashboard.py
```

**Dashboard URL:** http://localhost:8501

#### Dashboard Features:

1. **ğŸ“¤ Upload CSV** - Batch process transaction files
2. **ğŸ“Š View Predictions** - See fraud probabilities for each transaction
3. **ğŸ” SHAP Explanations** - Understand why transactions were flagged
4. **ğŸ“ˆ Risk Distribution** - Visualize fraud score distribution
5. **ğŸšï¸ Threshold Adjuster** - Tune detection sensitivity
6. **ğŸ’¾ Export Results** - Download flagged transactions

#### Example Usage:
```python
# Upload a CSV with these columns:
# amount_usd, merchant_category, merchant_country, channel,
# card_present, customer_age_days, customer_txn_30d,
# avg_amount_30d, std_amount_30d, country_mismatch,
# hour_of_day, is_weekend
```

---

### Flask REST API

Start the API server:
```bash
python src/serve_api.py
```

**API Base URL:** http://localhost:5000

#### API Endpoints:

##### 1. Health Check
```bash
curl http://localhost:5000/health
```

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true
}
```

##### 2. Score Transaction (Single)
```bash
curl -X POST http://localhost:5000/score \
  -H "Content-Type: application/json" \
  -d '{
    "records": [{
      "amount_usd": 1250.00,
      "merchant_category": "electronics",
      "merchant_country": "CN",
      "channel": "online",
      "card_present": 0,
      "customer_age_days": 45,
      "customer_txn_30d": 3,
      "avg_amount_30d": 150.00,
      "std_amount_30d": 75.00,
      "country_mismatch": 1,
      "hour_of_day": 2,
      "is_weekend": 0
    }]
  }'
```

**Response:**
```json
{
  "fraud_probability": [0.912],
  "predictions": [1],
  "model_version": "1.0",
  "timestamp": "2025-11-05T10:30:00Z"
}
```

##### 3. Batch Scoring
```bash
curl -X POST http://localhost:5000/score \
  -H "Content-Type: application/json" \
  -d @transactions.json
```

**transactions.json example:**
```json
{
  "records": [
    {"amount_usd": 50.0, "merchant_category": "grocery", ...},
    {"amount_usd": 1500.0, "merchant_category": "electronics", ...},
    {"amount_usd": 25.0, "merchant_category": "restaurant", ...}
  ]
}
```

---

### Jupyter Notebooks

Explore the project interactively:
```bash
jupyter notebook notebooks/
```

#### Notebooks:

1. **`01_eda.ipynb`** - Exploratory Data Analysis
   - Dataset overview & statistics
   - Fraud distribution analysis
   - Feature analysis by fraud status
   - Temporal patterns
   - 15+ visualizations

2. **`02_train_model.ipynb`** - Interactive Model Training
   - Data preprocessing
   - Model training with cross-validation
   - Feature importance analysis
   - Threshold optimization
   - Performance evaluation

3. **`03_explainability.ipynb`** - SHAP Deep Dive
   - Global feature importance
   - Local explanations (force plots)
   - Dependence plots
   - Feature interactions
   - False positive analysis

---

## ğŸ“Š Model Performance

### Evaluation Metrics (Test Set)

| Metric | Score | Description |
|--------|-------|-------------|
| **ROC-AUC** | 0.95+ | Overall discrimination ability |
| **PR-AUC** | 0.85+ | Performance on imbalanced data |
| **Recall @ Top 1%** | 70%+ | Fraud caught in highest risk 1% |
| **Precision @ Top 1%** | 60%+ | Accuracy of top 1% flagged |
| **F1-Score** | 0.75+ | Harmonic mean of precision/recall |

### Confusion Matrix (Threshold = 0.5)
```
                 Predicted
                Normal  Fraud
Actual  Normal   19,650   50
        Fraud       90   210
```

- **True Positives:** 210 frauds correctly identified
- **False Positives:** 50 normal transactions flagged (0.25%)
- **False Negatives:** 90 frauds missed (30%)
- **True Negatives:** 19,650 normal transactions correctly cleared

### Feature Importance (Top 10)

1. **transaction_amount** - Higher amounts increase fraud likelihood
2. **country_mismatch** - Transactions from unusual countries
3. **channel_online** - Online channels have higher fraud rates
4. **card_not_present** - CNP transactions are riskier
5. **customer_age_days** - Newer accounts more vulnerable
6. **hour_of_day** - Late night/early morning suspicious
7. **merchant_category** - Electronics/travel higher risk
8. **std_amount_30d** - Unusual spending patterns
9. **customer_txn_30d** - Transaction velocity
10. **avg_amount_30d** - Deviation from normal spending

---

## ğŸ“¡ API Documentation

### Base URL
```
http://localhost:5000
```

### Authentication

Currently no authentication required (add for production deployment).

### Request Format

All POST requests must include:
- Header: `Content-Type: application/json`
- Body: JSON with `records` array

### Response Format
```json
{
  "fraud_probability": [0.05, 0.92, 0.15],
  "predictions": [0, 1, 0],
  "model_version": "1.0",
  "timestamp": "2025-11-05T10:30:00Z",
  "processing_time_ms": 45
}
```

### Error Responses

**400 Bad Request:**
```json
{
  "error": "Invalid input format",
  "message": "Missing required field: amount_usd"
}
```

**500 Internal Server Error:**
```json
{
  "error": "Model prediction failed",
  "message": "Contact support"
}
```

### Rate Limits

- Development: No limits
- Production: Implement rate limiting (e.g., 1000 requests/hour)

---

## ğŸ” Explainability (SHAP)

### What is SHAP?

SHAP (SHapley Additive exPlanations) provides transparent explanations for each prediction by calculating the contribution of each feature.

### Global Explanations

**Summary Plot** shows which features are most important overall:
```python
from src.explain import create_shap_explainer, plot_shap_summary

# Create explainer
explainer = create_shap_explainer(model, X_train)

# Generate summary plot
plot_shap_summary(explainer, X_test, save_path='reports/shap_summary.png')
```

**Interpretation:**
- Features at the top have the highest impact
- Red = high feature value, Blue = low feature value
- Position on X-axis shows impact direction (positive = fraud)

### Local Explanations

**Force Plot** explains a single prediction:
```python
from src.explain import explain_prediction

# Explain a specific transaction
explanation = explain_prediction(
    model, 
    preprocessor, 
    transaction_data, 
    transaction_index=0
)
```

**Interpretation:**
- Base value: Average model output
- Red arrows: Features pushing toward fraud
- Blue arrows: Features pushing toward normal
- Final prediction: Where the arrows end

### Why Explainability Matters

1. **Regulatory Compliance** - Explain decisions to regulators
2. **Analyst Trust** - Help fraud analysts understand flags
3. **Model Debugging** - Identify biases or errors
4. **Customer Communication** - Explain account freezes
5. **Continuous Improvement** - Identify new fraud patterns

---

## ğŸ³ Docker Deployment

### Build Docker Image
```bash
docker build -t fraud-detection:latest .
```

### Run API Container
```bash
docker run -p 5000:5000 fraud-detection:latest
```

API available at: http://localhost:5000

### Run Dashboard Container
```bash
docker run -p 8501:8501 fraud-detection:latest \
  streamlit run src/app_dashboard.py --server.address=0.0.0.0
```

Dashboard available at: http://localhost:8501

### Using Docker Compose
```bash
# Start all services
docker-compose up -d

# Stop all services
docker-compose down
```

**Services:**
- API: http://localhost:5000
- Dashboard: http://localhost:8501

### Volume Mounts (Persist Models)
```bash
docker run -p 5000:5000 \
  -v $(pwd)/models:/app/models \
  fraud-detection:latest
```

---

## ğŸ—ï¸ Project Architecture

### Data Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Data       â”‚
â”‚  transactions   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Feature Eng.   â”‚
â”‚  Preprocessing  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  XGBoost Model  â”‚
â”‚  Training       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SHAP           â”‚
â”‚  Explainer      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼              â–¼              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Flask  â”‚    â”‚Streamlitâ”‚   â”‚Notebooks â”‚
    â”‚  API   â”‚    â”‚Dashboardâ”‚   â”‚          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

**Machine Learning:**
- XGBoost 2.0+ (gradient boosting)
- scikit-learn 1.3+ (preprocessing, metrics)
- imbalanced-learn 0.11+ (handling class imbalance)

**Explainability:**
- SHAP 0.42+ (Shapley values)

**Web Frameworks:**
- Streamlit 1.28+ (dashboard)
- Flask 3.0+ (REST API)

**Data & Visualization:**
- pandas 2.0+ (data manipulation)
- matplotlib 3.7+ (plotting)
- seaborn 0.12+ (statistical viz)
- plotly 5.14+ (interactive charts)

**Development:**
- Jupyter 1.0+ (notebooks)
- Docker (containerization)

---

## ğŸ“‹ Model Card

### Intended Use

**Primary Use Case:**
Detect fraudulent financial transactions in real-time or batch processing.

**Intended Users:**
- Fraud analysts
- Risk management teams
- Financial institutions
- Payment processors

**Out-of-Scope:**
- Credit scoring
- Customer segmentation
- Marketing analytics

### Model Details

- **Model Type:** XGBoost Binary Classifier
- **Version:** 1.0
- **Training Date:** November 2025
- **Training Data:** 100,000 synthetic transactions (80/20 train/test split)
- **Features:** 30+ engineered features (numeric + categorical)

### Performance

- Optimized for high recall at top percentiles
- Handles severe class imbalance (98.5% normal, 1.5% fraud)
- Sub-second prediction latency

### Limitations

1. **Synthetic Data:** Trained on simulated data; real-world performance may vary
2. **Drift:** Model may degrade over time as fraud patterns evolve
3. **Bias:** May have geographic or demographic biases in synthetic data
4. **False Positives:** ~0.25% of normal transactions flagged at default threshold

### Ethical Considerations

- **Fairness:** Monitor for disparate impact across customer segments
- **Transparency:** SHAP provides explanations for all decisions
- **Privacy:** No PII used in model features
- **Human Oversight:** Flagged transactions should be reviewed by analysts

### Recommendations

- Retrain model monthly with new fraud patterns
- Monitor performance metrics continuously
- Conduct bias audits quarterly
- Implement human review for all flagged transactions
- Provide customers ability to appeal decisions

**Full Model Card:** See `reports/model_card.md`

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

### Areas for Improvement

1. **Additional Features:**
   - Graph-based fraud detection (NetworkX)
   - Velocity checks (transactions per hour)
   - Device fingerprinting
   - IP geolocation

2. **Model Enhancements:**
   - Try LightGBM or CatBoost
   - Hyperparameter tuning (Optuna)
   - Ensemble methods
   - Deep learning models

3. **Dashboard Features:**
   - Real-time monitoring
   - Alert notifications (email/Slack)
   - Case management system
   - Analyst feedback loop

4. **API Improvements:**
   - Authentication (JWT)
   - Rate limiting
   - API versioning
   - Comprehensive logging

5. **Testing:**
   - Unit tests
   - Integration tests
   - Load testing
   - CI/CD pipeline

### How to Contribute

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
```
MIT License

Copyright (c) 2025 David Madison

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
```

---

## ğŸ™ Acknowledgments

- **XGBoost Team** - For the excellent gradient boosting library
- **SHAP Developers** - For making ML models interpretable
- **Streamlit Team** - For the intuitive dashboard framework
- **Flask Community** - For the lightweight web framework
- **scikit-learn Contributors** - For comprehensive ML tools

---

## ğŸ“ Contact & Support

- **Author:** David Madison
- **GitHub:** [@davidmadison95](https://github.com/davidmadison95)
- **Project Link:** [https://github.com/davidmadison95/fraud-detection-xai](https://github.com/davidmadison95/fraud-detection-xai)

### Getting Help

1. **Documentation:** Check `docs/` folder for detailed guides
2. **Issues:** Open a GitHub issue for bugs or feature requests
3. **Discussions:** Use GitHub Discussions for questions

---

## ğŸ“Š Project Statistics

- **Lines of Code:** ~5,000+
- **Lines of Documentation:** ~2,000+
- **Files:** 19+ (modules, notebooks, docs)
- **Dependencies:** 20+ Python packages
- **Test Coverage:** Comprehensive evaluation metrics
- **Dataset:** 100,000 synthetic transactions

---

## ğŸ¯ Use Cases

### Financial Institutions
- Real-time transaction monitoring
- Batch fraud detection on historical data
- Investigation tool for fraud analysts

### Fintech Companies
- API integration for payment processing
- Risk scoring for new accounts
- Compliance reporting

### Research & Education
- Study explainable AI techniques
- Learn end-to-end ML engineering
- Understand fraud detection methods

---

## ğŸš€ Roadmap

### Version 1.0 (Current)
- âœ… XGBoost fraud detection
- âœ… SHAP explainability
- âœ… Streamlit dashboard
- âœ… Flask REST API
- âœ… Docker support

### Version 1.1 (Planned)
- ğŸ”„ Authentication & authorization
- ğŸ”„ Real-time monitoring dashboard
- ğŸ”„ Advanced visualization options
- ğŸ”„ Model retraining automation

### Version 2.0 (Future)
- ğŸ“… Graph-based fraud detection
- ğŸ“… Deep learning models
- ğŸ“… Auto-ML capabilities
- ğŸ“… Kubernetes deployment

---

## â­ Star History

If you find this project useful, please consider giving it a star! â­

---

**Built with â¤ï¸ using Python, XGBoost, SHAP, Streamlit, and Flask**

*Last Updated: November 2025*
